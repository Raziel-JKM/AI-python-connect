{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "N431a_Auto_New.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKF5wR4A4f6",
        "outputId": "504ee292-42e2-421a-cd2e-e7291fdb5b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10OXb-oNKVzO"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 3 / Assignment 1*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "케라스를 이용한 바이너리 이미지 분류 모델에 3가지 CNN 모델을 적용하여 보는 과제입니다. <br/>\n",
        "\n",
        "- [데이터 다운로드](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/datasets/mountainForest.zip)\n",
        "\n",
        "산의 이미지(./data/mountin/*)와 숲의 이미지(./data/forest/*)를 분류하는 문제입니다. <br/>\n",
        "산을 Positive (1)로, 숲 이미지를 Negative(0)로 레이블링 하여줍니다.\n",
        "\n",
        "클래스당 약 350개의 이미지로 이루어져 있는데요.<br/>\n",
        "표본이 작다는 점을 감안하면 현실적으로 어려운 문제입니다.\n",
        "\n",
        "하지만 이번 과제에서는 해당 데이터에 여러 가지 모델을 적용해보는는 것에 중점을 두어 봅시다. <br/>\n",
        "과제를 통해 이미지 분류에 적용할 수 있는 여러 모델을 알아보고 서로를 비교하는 데 익숙해져 보면 좋겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Ng0p_35yrh"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI3qR2nVKVzT"
      },
      "source": [
        "## Part 1 : Pre-trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXXsDSZvriLL"
      },
      "source": [
        "Keras에서 제공하는 pre-trained 모델인 ResNet50을 불러와서 사용해봅니다. [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1)은 50 개의 layer를 가진  CNN기반의 모델입니다. <br/>\n",
        "이미지를 [1000 개의 클래스로](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt)를 분류하는 모델인데요. 우리가 풀어야 할 과제는 2가지 이므로 마지막 출력단을 변경해서 사용해 볼 수 있습니다.\n",
        "\n",
        "\n",
        "`ResNet50`을 불러올 때, **`include_top=False`** 로 하면, 기존 1000가지 클래스로의 분류 문제를 풀 수 있는 ResNet 모델에서 Fully Connected layer 부분을 제거해주는 역할을 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHZAR2pnyD65"
      },
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D()\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Km6oGLqP0z"
      },
      "source": [
        "아래 부분은 ResNet50 레이어들의 파라미터를 학습하지 않도록 설정합니다. <br/>\n",
        "이렇게 설정된 매개 변수는 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트 되지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Kn76NkyIgG"
      },
      "source": [
        "```python\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qg5wDPPqV0P"
      },
      "source": [
        "모델에 추가로 **`Fully-conneted layer(Dense)`** 를 추가해야 합니다. <br/>\n",
        "사전 학습 모델을 불러오면서 최상위 레이어인 **`Fully-conneted layer`** 를 제거했기 때문이지요.\n",
        "\n",
        "새로 추가하는 **`Fully-conneted layer`** 에서는 목적인 이진 분류에 맞게 출력층을 설계하여 주어야 합니다. <br/> **`GlobalAveragePooling2D`** 레이어는 마지막 컨벌루션 레이어 출력(2 차원) 각각의 평균을 취해주어 **`Dense`** 층에 들어갈 수 있도록 해줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfCWu5bJyNoW"
      },
      "source": [
        "```python\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x) # 출력층을 설계합니다.\n",
        "model = Model(resnet.input, predictions)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvJd3ItAKVzU"
      },
      "source": [
        "### Load in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcetvpqwO5X"
      },
      "source": [
        "[Keras ImageDataGenerator](https://keras.io/api/preprocessing/image/) 를 참고하여 데이터를 불러옵니다. <br/>\n",
        "위 링크뿐만 아니라 구글링을 통해 ImageDataGenerator 라이브러리에 대한 여러 예제를 조사하고 참고해보세요. \n",
        "\n",
        "Notebook을 여러분의 Google Drive에 Mount 한 후에 이미지를 불러오도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4c0M58cKVzW"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        " \n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model # This is the functional API\n",
        " \n",
        "resnet = ResNet50(weights='imagenet', include_top=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z03y0QP6CWS0"
      },
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/RazielData/mountainForest'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "train_forest_dir = os.path.join(train_dir, 'forest')\n",
        "train_mountain_dir = os.path.join(train_dir, 'mountain')\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "validation_forest_dir = os.path.join(validation_dir, 'forest')\n",
        "validation_mountain_dir = os.path.join(validation_dir, 'mountain')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Q1IP99CeIH",
        "outputId": "d3f755c7-212d-4171-8d76-86910f9c3996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_forest_fnames = os.listdir(train_forest_dir)\n",
        "train_forest_fnames.sort()\n",
        "print(train_forest_fnames[:10])\n",
        "\n",
        "train_mountain_fnames = os.listdir(train_mountain_dir)\n",
        "train_mountain_fnames.sort()\n",
        "print(train_mountain_fnames[:10])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.DS_Store', '.ipynb_checkpoints', 'art114.jpg', 'for102.jpg', 'for105.jpg', 'for106.jpg', 'for110.jpg', 'for112.jpg', 'for114.jpg', 'for116.jpg']\n",
            "['.DS_Store', '.ipynb_checkpoints', 'art1131.jpg', 'art1132.jpg', 'gre242.jpg', 'land10.jpg', 'land11.jpg', 'land13.jpg', 'land130.jpg', 'land131.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qkQg8BBChPS"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EldsmBydCj-y"
      },
      "source": [
        "img_input = layers.Input(shape=(224*224*3))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNaliDMbCmdW",
        "outputId": "02ec9516-996e-471e-959e-7eb4fa4e6930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  \n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 533 images belonging to 2 classes.\n",
            "Found 195 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zh85TQsCqpg"
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep2HytMuCtkc"
      },
      "source": [
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIJ3yr7uDPrr"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7tcAY5_DSs8",
        "outputId": "f6bdc3f3-c7cb-4088-b74f-a449d8ffa2cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=27,  \n",
        "      epochs=2,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=10,\n",
        "      verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "27/27 [==============================] - 17s 494ms/step - loss: 0.8607 - accuracy: 0.5272 - val_loss: 0.6505 - val_accuracy: 0.6513\n",
            "Epoch 2/2\n",
            "27/27 [==============================] - 12s 458ms/step - loss: 0.6142 - accuracy: 0.6735 - val_loss: 0.5446 - val_accuracy: 0.6769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnO-Y6kADqRD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import color, io\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jAKOcHODv4k"
      },
      "source": [
        "file_extension = \"*.jpg\"\n",
        "\n",
        "train_forest_ic = io.imread_collection(os.path.join(train_forest_dir, file_extension))\n",
        "train_mountain_ic = io.imread_collection(os.path.join(train_mountain_dir, file_extension))\n",
        "validation_forest_ic = io.imread_collection(os.path.join(validation_forest_dir, file_extension))\n",
        "validation_mountain_ic = io.imread_collection(os.path.join(validation_mountain_dir, file_extension))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6LtYk9DyZv",
        "outputId": "f582ac08-3d93-44ff-d06e-75999589ea72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "y_forest_train = np.zeros(len(train_forest_ic.files))\n",
        "y_mountain_train = np.zeros(len(train_mountain_ic.files))\n",
        "y_forest_validation = np.ones(len(validation_forest_ic.files))\n",
        "y_mountain_validation = np.ones(len(validation_mountain_ic.files))\n",
        "\n",
        "print(y_forest_train.shape, y_mountain_train.shape, y_forest_validation.shape, y_mountain_validation.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(268,) (252,) (60,) (122,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak_RCM25D1F0"
      },
      "source": [
        "train_forest_ic = [resize(img, (224, 224)) for img in train_forest_ic]\n",
        "train_mountain_ic = [resize(img, (224, 224)) for img in train_mountain_ic]\n",
        "validation_forest_ic = [resize(img, (224, 224)) for img in validation_forest_ic]\n",
        "validation_mountain_ic = [resize(img, (224, 224)) for img in validation_mountain_ic]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEuMTntcD3dZ"
      },
      "source": [
        "X_train, y_train = np.concatenate((train_forest_ic, train_mountain_ic)), np.concatenate((y_forest_train, y_mountain_train))\n",
        "X_validation, y_validation = np.concatenate((validation_forest_ic, validation_mountain_ic)), np.concatenate((y_forest_validation, y_mountain_validation))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzezBMBKVza"
      },
      "source": [
        "### Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE2vB2jlD_aH"
      },
      "source": [
        "resnet = ResNet50(weights='imagenet', include_top=False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9lenvylECWj"
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtQX3ALdKVzf"
      },
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25WT5UeUEGiK"
      },
      "source": [
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOkAmBGxEJIb",
        "outputId": "3fad4806-db08-4034-a104-f110537ae9c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=15,\n",
        "    verbose=1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "17/17 [==============================] - 11s 430ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - 7s 435ms/step - loss: 1.5221e-11 - accuracy: 1.0000\n",
            "Epoch 3/15\n",
            "17/17 [==============================] - 8s 446ms/step - loss: 2.1772e-12 - accuracy: 1.0000\n",
            "Epoch 4/15\n",
            "17/17 [==============================] - 7s 433ms/step - loss: 1.5443e-12 - accuracy: 1.0000\n",
            "Epoch 5/15\n",
            "17/17 [==============================] - 8s 455ms/step - loss: 1.4516e-12 - accuracy: 1.0000\n",
            "Epoch 6/15\n",
            "17/17 [==============================] - 8s 447ms/step - loss: 1.4348e-12 - accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "17/17 [==============================] - 8s 446ms/step - loss: 1.4317e-12 - accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "17/17 [==============================] - 8s 461ms/step - loss: 1.4312e-12 - accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "17/17 [==============================] - 8s 460ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "17/17 [==============================] - 8s 461ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "17/17 [==============================] - 8s 453ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "17/17 [==============================] - 8s 463ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "17/17 [==============================] - 8s 462ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "17/17 [==============================] - 8s 452ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "17/17 [==============================] - 8s 453ms/step - loss: 1.4311e-12 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0cc7a467d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spkex121EOO3",
        "outputId": "9bd48bfc-cd46-4407-9f0b-3f8d7410be5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(X_validation, y_validation)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 4s 432ms/step - loss: 27.5236 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27.52364730834961, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBDRtCw55Sb"
      },
      "source": [
        "## Part 2 : Custom CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gpEjsFpKVzj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "이 단계에서는 Keras를 사용하여 자신 만의 CNN을 작성하고 훈련합니다. <br/>\n",
        "네트워크에 적어도 하나의 Conv 레이어와 pooling 레이어가있는 아키텍처를 만들어 사용해 보세요. <br/> 아래는 여러분이 참고할 수 있도록 표시한 결과이며 여러분의 마음대로 설계하여도 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St--__KE0mN5"
      },
      "source": [
        "### Make a Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx_EG-pOERcg"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9HcxllWEUXx"
      },
      "source": [
        "model_scratch = Sequential()\n",
        "model_scratch.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
        "model_scratch.add(MaxPooling2D(2,2))\n",
        "model_scratch.add(Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
        "model_scratch.add(MaxPooling2D(2,2))\n",
        "model_scratch.add(Flatten())\n",
        "model_scratch.add(Dense(128, activation='relu'))\n",
        "model_scratch.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXbzUP8cEXSv",
        "outputId": "55870e57-6f0b-431f-d891-757c0c07d2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_scratch.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 200704)            0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               25690240  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 25,709,761\n",
            "Trainable params: 25,709,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS18U9mP0f2F"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5NrX3K9KVzm"
      },
      "source": [
        "# Compile Model\n",
        "model_scratch.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqy74Fpo0jXi"
      },
      "source": [
        "### Fit Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yju2nvVNKVzp",
        "outputId": "438f8d3f-c6ca-461a-caba-4ebb7ff718fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit Model\n",
        "model_scratch.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_validation, y_validation))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "17/17 [==============================] - 7s 401ms/step - loss: 0.0531 - accuracy: 0.9385 - val_loss: 112.8856 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "17/17 [==============================] - 7s 390ms/step - loss: 6.8911e-26 - accuracy: 1.0000 - val_loss: 112.8856 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "17/17 [==============================] - 7s 388ms/step - loss: 6.8911e-26 - accuracy: 1.0000 - val_loss: 112.8856 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "17/17 [==============================] - 7s 398ms/step - loss: 6.8911e-26 - accuracy: 1.0000 - val_loss: 112.8856 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "17/17 [==============================] - 7s 391ms/step - loss: 6.8911e-26 - accuracy: 1.0000 - val_loss: 112.8856 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0cf0d6e790>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}